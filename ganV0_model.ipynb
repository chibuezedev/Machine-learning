{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker tensorflow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "\n",
        "# Initialize Faker for synthetic data generation\n",
        "fake = Faker()\n",
        "\n",
        "# Generate a small dataset to train the GAN\n",
        "def create_real_data(num_samples):\n",
        "    records = []\n",
        "    for _ in range(num_samples):\n",
        "        amount = round(np.random.uniform(10.0, 2000.0), 2)\n",
        "        card_type = random.choice(['visa', 'mastercard', 'amex'])\n",
        "        timestamp = fake.date_time_this_year()\n",
        "        location = np.random.choice(['New York', 'Los Angeles', 'San Francisco', 'Houston', 'Chicago'])\n",
        "        transaction_type = random.choice(['Purchase', 'Refund', 'Cash Withdrawal'])\n",
        "        card_number = fake.credit_card_number(card_type=card_type)\n",
        "        masked_card_number = f\"{card_number[:4]} ******** {card_number[-4:]}\"\n",
        "        records.append([masked_card_number, card_type, timestamp, amount, transaction_type, location])\n",
        "    return np.array(records)\n",
        "\n",
        "# Create a dataset of real transactions\n",
        "real_data = create_real_data(1000)  # Create 1000 samples for training\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(data):\n",
        "    amounts = data[:, 3].astype(np.float32)\n",
        "    card_types = data[:, 1]\n",
        "    locations = data[:, 5]\n",
        "    transaction_types = data[:, 4]\n",
        "\n",
        "    card_type_encoded = pd.get_dummies(card_types, drop_first=True)\n",
        "    location_encoded = pd.get_dummies(locations, drop_first=True)\n",
        "    transaction_type_encoded = pd.get_dummies(transaction_types, drop_first=True)\n",
        "\n",
        "    processed_data = np.hstack((amounts.reshape(-1, 1), card_type_encoded.values, location_encoded.values.astype(np.float32), transaction_type_encoded.values))\n",
        "\n",
        "    assert processed_data.shape[1] == 9, f\"Expected 9 features, got {processed_data.shape[1]}\"\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "processed_real_data = preprocess_data(real_data)\n",
        "\n",
        "# Create the generator model\n",
        "def build_generator():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(128, activation='relu', input_dim=10))\n",
        "    model.add(layers.Dense(9, activation='linear'))  # Changed to 9 to match processed data shape\n",
        "    return model\n",
        "\n",
        "# Create the discriminator model\n",
        "def build_discriminator():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(128, activation='relu', input_shape=(9,)))  # Changed to (9,) to match processed data shape\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Build and compile the models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Create the GAN model\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = keras.Sequential([generator, discriminator])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Training the GAN\n",
        "def train_gan(epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, processed_real_data.shape[0], batch_size)\n",
        "        real_samples = processed_real_data[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 10))\n",
        "        fake_samples = generator.predict(noise)\n",
        "\n",
        "        real_labels = np.ones((batch_size, 1))\n",
        "        fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_samples, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(fake_samples, fake_labels)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 10))\n",
        "        g_loss = gan.train_on_batch(noise, real_labels)\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            print(f\"{epoch + 1}/{epochs} [D loss: {d_loss[0]:.4f}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
        "\n",
        "# Train the GAN for 50 epochs with a batch size of 32\n",
        "train_gan(epochs=50, batch_size=32)\n",
        "\n",
        "# Generate synthetic data using the trained generator\n",
        "def generate_synthetic_data(num_samples):\n",
        "    noise = np.random.normal(0, 1, (num_samples, 10))\n",
        "    generated_samples = generator.predict(noise)\n",
        "\n",
        "    amounts = generated_samples[:, 0]\n",
        "    card_types_encoded = generated_samples[:, 1:3]  # Adjusted to match the new shape\n",
        "    locations_encoded = generated_samples[:, 3:7]  # Adjusted to match the new shape\n",
        "    transaction_types_encoded = generated_samples[:, 7:]  # Adjusted to match the new shape\n",
        "\n",
        "    card_types = np.argmax(card_types_encoded, axis=1)\n",
        "    locations = np.argmax(locations_encoded, axis=1)\n",
        "    transaction_types = np.argmax(transaction_types_encoded, axis=1)\n",
        "\n",
        "    card_type_names = ['visa', 'mastercard', 'amex']\n",
        "    location_names = ['New York', 'Los Angeles', 'San Francisco', 'Houston', 'Chicago']\n",
        "    transaction_type_names = ['Purchase', 'Refund', 'Cash Withdrawal']\n",
        "\n",
        "    card_type_output = [card_type_names[i] for i in card_types]\n",
        "    location_output = [location_names[i] for i in locations]\n",
        "    transaction_type_output = [transaction_type_names[i] for i in transaction_types]\n",
        "\n",
        "    transaction_ids = np.arange(1, num_samples + 1)\n",
        "    card_numbers = [f\"{random.randint(1000, 9999)} ******** {random.randint(1000, 9999)}\" for _ in range(num_samples)]\n",
        "    timestamps = [fake.date_time_this_year() for _ in range(num_samples)]\n",
        "\n",
        "    return np.column_stack((transaction_ids, card_numbers, card_type_output, timestamps, amounts, transaction_type_output, location_output))\n",
        "\n",
        "# Generate 500 synthetic transaction samples\n",
        "synthetic_data = generate_synthetic_data(500)\n",
        "\n",
        "# Convert synthetic data to DataFrame for easy viewing\n",
        "synthetic_df = pd.DataFrame(synthetic_data, columns=['Transaction ID', 'Card Number', 'Card Type', 'Transaction Date & Time', 'Amount', 'Transaction Type', 'Location'])\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# Optionally, save to CSV\n",
        "synthetic_df.to_csv('synthetic_transaction_data_gan.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K0EpDhIfhTt",
        "outputId": "cee6b66e-7c26-4348-ea7a-4163f7288eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-30.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-30.4.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.4/1.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-30.4.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    }
  ]
}
